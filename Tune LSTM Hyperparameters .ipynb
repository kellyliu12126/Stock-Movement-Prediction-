{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import  keras\n",
    "import  tensorflow as  tf  \n",
    "#print(keras.__version__)\n",
    "#print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n"
     ]
    }
   ],
   "source": [
    "import numpy \n",
    "import pandas \n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import datetime\n",
    "import math\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "import matplotlib\n",
    "\n",
    "# be able to save images on server\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 968 entries, 15-01-02 to 18-11-08\n",
      "Data columns (total 1 columns):\n",
      "AMClose    968 non-null float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 15.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMClose</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15-01-02</th>\n",
       "      <td>2.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-01-05</th>\n",
       "      <td>2.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-01-06</th>\n",
       "      <td>2.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-01-07</th>\n",
       "      <td>2.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-01-08</th>\n",
       "      <td>2.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AMClose\n",
       "Date             \n",
       "15-01-02     2.08\n",
       "15-01-05     2.20\n",
       "15-01-06     2.21\n",
       "15-01-07     2.22\n",
       "15-01-08     2.21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import all stock prices \n",
    "df = pandas.read_csv(\"/Users/kellyliu/Desktop/HMM/WWWWR.csv\", index_col = 0)\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load Dataset, covert ID to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2015-01-02    2.08\n",
      "2015-01-05    2.20\n",
      "2015-01-06    2.21\n",
      "2015-01-07    2.22\n",
      "2015-01-08    2.21\n",
      "Name: AMClose, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3Xl8XHW5+PHPM1v2NE2Tlq60pQtl\nKS0Uyr7IoiwKKoioiMqFe/EqKm6g/Lx6RUTv9YLLRUVRiwKCgsIFWcsuS2nLUkqB7mvapGna7Jnt\n+f1xzqSTZpLOTCaz5Xm/Xn1lzplzZp6cJk++85zvIqqKMcaYwufJdQDGGGMywxK6McYUCUvoxhhT\nJCyhG2NMkbCEbowxRcISujHGFAlL6MYYUyQsoRtjTJGwhG6MMUXCl803q6ur06lTp2bzLY0xpuAt\nW7Zsp6rW7++4rCb0qVOnsnTp0my+pTHGFDwR2ZjMcVZyMcaYImEJ3RhjioQldGOMKRKW0I0xpkhY\nQjfGmCJhCd0YY4qEJXRjjMkD63d20NjaPaTXyGo/dGOMMYmd9t/PALDhpnPTfg1roRtjTJGwhG6M\nMUXCEroxxhQJS+jGGFMkLKEbY0yORaKakdfZb0IXkdki8nrcv1YR+bKI1IrIEyKy2v06OiMRGWPM\nCNMTjmTkdfab0FX1XVWdp6rzgKOATuBvwLXAYlWdCSx2t40xxqSoOxTNyOukWnI5HVirqhuB84FF\n7v5FwAUZicgYY0aYrLXQ9/Fx4G738ThVbQBwv47NSETGGDPC9GS7hS4iAeBDwF9SeQMRuVJElorI\n0qamplTjM8aYotedgxb62cByVd3hbu8QkfEA7tfGRCep6m2qukBVF9TX73dJPGOMKSpdwQg723sG\nPSbrLXTgEvaWWwAeBC5zH18GPJCRiIwxpohc+celLLjhSa67f8WAk291h7LYQheRcuBM4P643TcB\nZ4rIave5mzISkTHGFJHnV+8E4O4lm7jn1c0APPTmNm78x6reY3rCmWmhJzXboqp2AmP22deM0+vF\nGGNMEmoqAoQjUb5w12sAfOP9s/F5PX0SuqoiImm9vo0UNcaYLNndEWTGtx/p3W7Y45Rg4ksuoUj6\no0YtoRtjTJbc/OR7fba73EQe30IPRtIvv1hCN8aYLNl3ypagm8jjBxaFhlBPt4RujDHDaHS5f8Dn\nYok8fuh/yFroxhiTn/xeD5ccM5kz5vQfTN+ToIVuJRdjjMlTXcEIpX4vngQ9V2Ill/gW+lAm6rKE\nbowxw0RV6QxFKA948Xr6J/RELfSuYPqDjCyhG2PMMAlGokSiSnnAN2gLPX7of2cwnPb7WUI3xphh\nEmttl/m9eBK00GP9z+Pr5p1DmAbAEroxxgyTWD/zsoAXb4LBnx09Tms8GNdVcSgll6SG/htjjEld\np5ucywN9W+izx1Xx7o42Hl7RQF1VCV2hCB5x+ql3WkI3xpj806fkEldDv/OKhZz846d5dUMLr25o\n6XOO1dCNMSYP7W2h+/C6Cf2widXUVZYwoaZs0HPSYQndGGOGyd4auqe35DJrbBUA137g4ITnWEI3\nxpg81OWWT8r8vt4boDPHVblfK/sdX+r39J6TjmQXuKgRkb+KyDsiskpEjhORWhF5QkRWu19Hpx2F\nMcYUofiboht3dQJwUH0F4EwJsK/ygC8rLfSfAo+q6sHAEcAq4FpgsarOBBa728YYY1yx5FwW8PZ2\nTawsdfqiBHx70++/njKdb58zhzK/d3hHiopINXAycDuAqgZVdTdwPrDIPWwRcEHaURhjTBHqikvo\nUXfu3IDbMo9voV939hyuOHk65QFvnxb6s+81MfXah5N+v2Ra6NOBJuD3IvKaiPxWRCqAcaraAOB+\n7T+VmDHGjFCNbd088lYDAOV+LxF1ErrPTeSBhCUXb5+Rorc9tzal90wmofuAI4Ffqup8oIMUyisi\ncqWILBWRpU1NTSkFZ4wxheqsm59j+abdgJPEI24L3e8OGfUnGDpaFvDSHddC1xRXo0smoW8Btqjq\nK+72X3ES/A4RGQ/gfm1MdLKq3qaqC1R1QX19fWrRGWNMgdrdGeqzHdmn5JJo9sXygI/O0DD2clHV\n7cBmEZnt7jodeBt4ELjM3XcZ8EDaURhjTBEJJlhGLqqxFrqTdiXB7Itl+9TQU22hJzv0/4vAnSIS\nANYBn8X5Y3CviFwObAIuSu2tjTGmOK1ubOu3L3ZT1Jdoli7Xvr1coilm9KQSuqq+DixI8NTpKb2b\nMcaMAO3d/csm4VhC9+wtjNxy8TwOmVDdu71vL5dU2eRcxhiTYaFI/5Z1rLUdl8+5YP7EPseUBby9\n0wUApFhxsaH/xhiTaaG4BSsOdVvgsZq5N0HtPKbc7yMYjvbeQE2VtdCNMSbD4lcg+uAREwD40+UL\nuf+1LdRWBAY8rzzgBZwpdKtK/Sk30a2FbowxGRZOUHKZfUAV1509J2HvlpgyN6HHboxqihndErox\nxmRYfMll4PTdX5k/1kJP78aoJXRjjMmw+JLL0dNqkz4vVnKJ3RgdrDWfiNXQjTEmw2It9Oe/cRqT\na8uTPq8s0LeFPqYiwMyxlWxM8nxroRtjTIbFaugVJam1mcsDzvGxGnooEk04b/pALKEbY0yGxVro\ng40KTSS+lwtAMKL4fZbQjTEmZ3rcuVwSTZE7mFiXxuaOIAChcJQSa6EbY0zutHWHCXg9lLq9VpI1\ntqoEr0fY2tIFuCUXX/KtfEvoxhiTYW3dIapKU+9z4vN6qCr10drtTL1rNXRjjMmxtu5w79qhqfJ7\nPb01+J6wJXRjjMmp9p5wWi10cOruwbDTSyYYiaZUh7eEbowxGdbWHaKqxJ/WuQHf3hZ6a1eI6rLk\nX8cSujHGZNhQSi6Nrd08+MY2olGlpTPEmEEm89pXUu8oIhuANiAChFV1gYjUAvcAU4ENwMdUtSXF\n2I0xpui0dadfculwBxWtbWonElVGp5DQU2mhn6aq81Q1tnLRtcBiVZ0JLHa3jTFmxGvrDlFdml7J\nJead7c4ydqm00IdScjkfWOQ+XgRcMITXMsaYoqCqtPeEqUxx2P++3tvhJPThaKEr8LiILBORK919\n41S1AcD9Ojb5UI0xpjh1BiNElbRLLjFb3MFFGa+hAyeo6jYRGQs8ISLvJPsG7h+AKwGmTJmSdGDG\nGFOI2twFoquGWHLZuttJ6BlvoavqNvdrI/A34Bhgh4iMB3C/Ng5w7m2qukBVF9TX1ycdmDHGFKL2\nHmeUZ7q9XL565iyA3uH/teUZTOgiUiEiVbHHwFnAW8CDwGXuYZcBD6QQszHGFKXW3hZ6egn9MydM\nBZwWekXA2ztHejKSecdxwN/clTN8wF2q+qiIvArcKyKXA5uAi1KM2xhjik6s5FKdZkKPn9Br1gFV\nKZ2733dU1XXAEQn2NwOnp/RuxhhTILpDEbbu7uKg+sqUzmt3E3plmiNF4+duOWrK6JTOtZGixhiT\nwFfvfYPTf/Js72ITyWpzZ0ocai8XgEmjy1I63hK6McYk8Ox7TQCE3ImyktU2xBo6QGxt6FRWKwJL\n6MYYk1A4Gu3zNVltPWFEoCKQfkL3e5zUnMrUuWAJ3RhjEorl8VAk1RZ6iMqAD48ntfVE43ndc1Nd\nws4SujHGJBBrmcemsk3WUCbmivG5Cd1a6MYYkwFRt2GeakJvH8LUuTFer9tCtxq6McZkTsoll57Q\nkIf9722hp1a2sYRujDGDSKeFPvSSi5OarYZujDEZlE4NfahT58Zuilq3RWOMyaBUSy4dwaEn9A53\nMFMqU+eCJXRjjBlUqi30nnCUkhRb1v3eM+y857jq0pTOG/rYVGOMKWI723tSOj4YjqbcO2Vfd15x\nLI+t3E5Fii19S+jGGJNAVamPtu4waxrbUzovEwl93uQa5k2uSfk8K7kYY3JGVVnV0IpqanXqbIi4\nHdFX70g+oe9s7yEc1ZQHBGWKJXRjTM68tLaZs3/6PIte3JDrUPqIRpXOYASA1Y1tSZ/37b+tAGDZ\nxpZhiWt/LKEbY3Jme2s3AK9t3p3jSPqK9TIJ+DxsaO6kJxxJ7ryeiPs1tSl3MyXphC4iXhF5TUQe\ncrenicgrIrJaRO4RkdT61xhjRrxYD5JclSgGEkvM8yfXEIkqG3Z2JnVerHYeTLFnTKakchW/BKyK\n2/4RcLOqzgRagMszGZgxpvh1h5zEN9SbiJkQiSqX3v4KL6zeSbvbwp46pgKA1zcnV0Ipd9f/LPEl\nvw5oJiV1FUVkEnAu8Ft3W4D3AX91D1kEXDAcARpjilcscQ6133Ym7Gzv4fnVO/ni3ctZvcOpmx80\n1kno37xvRVKvccy0WgB+8OHDhifI/Uj2Kt4CfAOIfY4YA+xW1VihaAswMcOxGWOKXGx5N4+kP3d4\npsT6m7d0hrjqzuUAzI9b0/OxldvpDg1eS4911qmvLBmeIPdjvwldRM4DGlV1WfzuBIcm7HckIleK\nyFIRWdrU1JRmmMaYYhSrVYdzVHN+9K0GfvToOwC8sHpnv+djJRSAf/3jMr567xuDvl7UzejeISxu\nMRTJtNBPAD4kIhuAP+OUWm4BakQkNjBpErAt0cmqepuqLlDVBfX19RkI2RhTLGIt9FA0N/3Q/+1P\ny/nlM2uJRJWV21r7PDdzbGW/2Q4fXtHAg28kTHXA3r7rkqNPHPtN6Kp6napOUtWpwMeBp1T1k8DT\nwIXuYZcBDwxblMaYohRrocfmLsmV7a3drG1qpzpu2tvqMn/C3jdX3/3agN0SYyWXfG6hD+SbwDUi\nsganpn57ZkIyxowUsf7e4Ry10GP2dIZY19TBR46c1LvvurMP7jN9bXyObmpLPL9LrOSSo3ye2lwu\nqvoM8Iz7eB1wTOZDMsaMFJ1uC70nHGH1jjZmjqvK2nvHDxZa3dhGVyjCrHFVPPTFExlV5mdybTmN\nbd29xzz79dM46cdPA84N1Kl1Ff1eM9Kb0AuvhW6MMUMSa6H/Y8V2zrz5OWZf/whbWpIbxDNUO/bs\nbWW/3eDUz6eOKeewiaOYXFsOgN9dOai61Mfk2nKevOYUADY094/xvR1trG/qACyhG2NGoH1r0T3h\nKP9c07+3yXDYtqer9/Gvn10HwLhRfecfjyXm2E3OaXUVlPm9rNy2p9/rnXXzc/xl2RYgdzV0mz7X\nGJMzHcH+/bo37+pKcGTmNezp/z77LihRWerj8Imj+NLpMwEnUR88vqpfj5h9FUQN3RhjMqkzroU+\nflQpoUiUXZ3BrLz3tt3dfbbPOmRcv6XjvB7h/754Yp99h06o5oHXtqGqA3ZPzNtui8YYMxw++PMX\n+rTQP3DYAVSW+Gjvzs5MhU1tPZT696bAn3zsiKTOm1BTRltPuHceGtjb/zzXLKEbY3Jixda+deia\nsgCVpT7aukNZef+ecISqUn/vdvzjwYwqc47b07U3zmz9EdofS+jGmLxQU+5na0sXT7/blJUbo92h\n9BZzLvM70wEsfmdH77745J5LltCNMXmhptxPS6eTGO95dfOwv19POEKp38t/XTiX+646LunzDqqv\nBODJt52Evm13F0+s2jHYKVljN0WNMXmhusxPmd9LVyjC1t2p9XRpbu/hy/e8zg0XHMaBY/oP+Ekk\n1kK/aMHklN7riMk1+DzC1LoKwpEox9/0VErnDydroRtj8kJNmb+3u9+2FBL6/72xjUtvX8Lzq3fy\nqdtfSfq8WAs9HeOqS/n9Pzfwyd/ufb+pY8rTeq1MsoRujMkLNeWB3u5+DXu693O0IxyJ8sW7X+sd\n6bl5VxcbmzuSOrc7FO3TyyUVVe4kXq+s39W77+GrT0rrtTLJEroxJi/UlPkTLrSQyI8ffYcX1+zk\nrQQDfJZvSm65uM5ghNI0l4qLXzN04bRaVn7v/VSU5L6CnfsIjDEGp4YeLxSJJpy+tr0nzK3PrOXW\nZ9b2me425tUNLXx4/qR+++Nt3tXJqoZWptSWpRXrzrjZFi897sC8SOZgLXRjTA5E4wbinDrbWfhm\n3/lPBlrubcPOvSWV1gT9v5du2NVv375+8LCz3v3+hvAPJPa+z3/jNM6bOyGt1xgO+fFnxRgzosQm\nxrr69Jlc/b4Z9MQWuIjL6V2hSMLBPrG1P/c1ubaM2eOqWfzOjkGH5QN0u1PnxuZoSdXscVW8u6ON\niTV9W/j3XXU8axrb0nrNTEhmTdFSEVkiIm+IyEoR+Z67f5qIvCIiq0XkHhEJDH+4xphisGGnM/3s\nsdNr8Xk9vSWL3356Qe8xPaHEqxg1t/ef6+WDR0zgjs8t5IhJo1Dd/1D87Xu6OWPO2JS7LMbcecVC\nHvzCCXj2+VRx1IGjufjoKWm9ZiYkU3LpAd6nqkcA84APiMixwI+Am1V1JtACXD58YRpjisn6ne0A\nTK+r7LN/4fQx/NeFcwH4zfPrEp7b3NG3hX7SzDp+fsl8ptVV9K4wFIoo7T1hrrnn9X6zKqoqG5s7\nk+6vnkhdZQlzJ9Wkff5wSWZNUVXVdnfT7/5TnMWi/+ruXwRcMCwRGmOKiqry/YecGva46pJ+z293\nuyze8dLGhOfHWuhXnz6TR750Er/7zNG9z8VuogYjURa9uIH7X9vKcT/sO/BnbVM7XaFIXvQbz7Sk\naugi4gWWATOA/wXWArtVNXZHYgswcVgiNMYUlZXbWnu7/SWqc39i4RR+8sR7XHbcgQnPv2fpZsZU\nBLjmzFn9ngt4ndcLhqN9FqFobO3mriWbuOuVTTS6PVSmDKGFnq+SSuiqGgHmiUgN8DdgTqLDEp0r\nIlcCVwJMmZK72pIxJj/sb6rwMZUllPo9fUZxdoci3PXKJo6eWsvuzoEnwoq10EORKG9t3duDZcmG\nXdzy5Oo+x87O4vql2ZJSt0VV3Y2zSPSxQI2IxP4gTAK2DXDObaq6QFUX1NfXDyVWY0wRiM0j/rWz\n+rewYwJez96eL8BvnlvHfz70Nvcs3TToawd8exP67s4gxx80BoB3t+/teTJjbCVHTK7hgH2WmysG\nyfRyqXdb5ohIGXAGsAp4GrjQPewy4IHhCtIYUzx63P7lC6bWDnhMwOfljS27efStBoDeMslgrXPo\n20LvDEaYN7mGiTVlvLyuGYCvv382T15zCg/8+wlD/j7yUTIt9PHA0yLyJvAq8ISqPgR8E7hGRNYA\nY4Dbhy9MY0yx6HITetkgE2OV+Dy8tmk3//an5QCE3W6Ia5ucQUX/fVHi1YViCf23z68nHFUqSnxM\nr6/g1Q3OdACHjK/OzDeRp/ZbQ1fVN4H5CfavA44ZjqCMMcUrVnIZbKbDQNzCE5/+3RKee68JgFXu\nJFwzxlYOcJ5ToP+zO596md/bZxGLfReBLjY29N8Yk1XJtNADcXO4xJJ5vIFmSRxT0bcbZHnAy4VH\n7R08VIx183g29N8Yk1Wxofu1lQMPLg8kWBpu1rhK3tvhDIkZaJbEwyaO6rN9/EF1lAX2Hju6PLl1\nQwuVtdCNMVm1fU83lSU+KgeZoTDRWp+HT9w7MrOuqv+AJHAm+PrfTxzZuz1lTDl1lQE+tmAS3/3g\nIYPO71IMrIVujMmqxrbuhCNE48Va6HPGV/fWzSfW7C2XDPbHYFpd3wFDIsKPL0x8E7XYWEI3xmTV\n9j3d+61lxxJ6VYmP9244m9++sI7PnTCNhdPH8M72wWcznFpXfEP6k2UJ3RiTVTtae1g4beA+6LD3\npqjfJwR8Hj5/6gwATphRxwkz6gY9tzwwctPayP3OjTFZF42qU3JJsoXu86R3m+9vnz+emvKRN6O3\nJXRjTNbs6gwSiijjBripGRNL6H5vejcx508ZndZ5hc56uRhjsmZHqzM17v5q6CW9Cd1SVCrsahlj\nsiaW0Pc3YrPM7xQPqhMsQWcGZiUXY0zW7Gh1BhXtL6F/7sSpHDKhmrMOHZeNsIqGJXRjTNZs39ON\nCNTvp4Y+aXQ5Fx41crsfpstKLsaYrGlq76G2PGC18WFiV9UYkzUtHUFqK0Zed8JssYRujMmKcCTK\nI29tZ/QI7B+eLZbQjTFZcecrzvJxSzbsynEkxSuZJegmi8jTIrJKRFaKyJfc/bUi8oSIrHa/jsye\n/MaYpDR3BHMdQtFLpoUeBr6qqnNwFof+dxE5BLgWWKyqM4HF7rYxxiQUW9Bi0edsobPhst+ErqoN\nqrrcfdyGs0D0ROB8YJF72CLgguEK0hiT36JR5br7V3D3kk0DHrO5pZPKEh8nzxx8ci2TvpRq6CIy\nFWd90VeAcaraAE7SB8ZmOjhjTP5TVf7jwZXcvWQT192/ot/zPeEIV9yxlLte2cQx02qLfpGJXEo6\noYtIJXAf8GVVbU3hvCtFZKmILG1q6r82oDGmsL20rpk/vrwRgFFlfprbe7jhobc57+fPo6r8bPFq\nnnh7B8B+p741Q5PUSFER8eMk8ztV9X539w4RGa+qDSIyHmhMdK6q3gbcBrBgwQLNQMzGmDzyXtyC\nE63dIRbeuJhw1PlV39UR5M9LNvc+f87hB2Q9vpEkmV4uAtwOrFLV/4l76kHgMvfxZcADmQ/PGJPv\nNu3qAuBrZ81Cld5kDvCLp9fQ3BFk/pQabv3kkYwfVZarMEeEZFroJwCXAitE5HV337eAm4B7ReRy\nYBNw0fCEaIzJZ5t2dXLwAVVMqOmfrH//zw0AnHv4eM45fHyWIxt59pvQVfUFYKC7GKdnNhxjTKHZ\nvKuTKWPKqSnfO9XtLRfP48v3vN67ffxBVjvPBptt0RiTNlVl065OTpxZ1zvh1nHTx/S5+bn+h+dY\nz5YssYRujEnbzvYgXaEIU2rLqat0psSdO3kUdZUBPnfCNC48apIl8yyyhG6MSdvKbXsAmDKmnDnj\nq7nvquOZO2kUIsJ3PnhIjqMbeSyhG2PS9pnfvwrAlFpnMYqjDrQpnXLJZls0xgzZxAQ9XEz2WQvd\nGJOWaFQJeD1cfPRkSt2Jt0xuWQvdGJOWxrYegpEosw6oynUoxmUJ3RiTlk27OoG99XOTe5bQjTFp\n2ewm9MmjrX6eLyyhG2OSoqpE4+Zp2dzSiQhMtISeNyyhmxFlV0eQa+59nY6ecK5DKTgX//plTvzR\nU73bm3Z1ckB1KSU+uyGaLyyhmxHlZ4tXc//yrXz8tpcz+rp/XrKJl9Y209odIhyJZvS188WSDbvY\ntqebi371Ivcv38L9y7dSFrBknk+s26IZUVSdksGKrXsy9prrd3ZwbdxKPf96ynS+dPpMygPF8evV\nFYxwzA+e7N1+dUMLr25oAeCA6tJchWUSsBa6GVHi5xXJVEt60Ysb+mz/+tl1HPKdx4hEi2M9l1Xb\nW2lzS1Q/ueiI3v0PfuEEbrl4Xq7CMglYQjcjSvw8UQ17unn0rQbuW7Yl7dfb3RnkD3EJ/er3zeh9\n/LFfv8SrG3al/dr5YttuZwGLf1x9Eh+eP7F3/9xJNYy1FnpeKY7PhMYkKb7VvGlXJ//2p+UAnHno\nOKpL/QOdNqAv3PUaANedfTDzJtdQX1XCz55awwHVpSzb2MIvn1nLgstGF/SMg0vW78LnEabXV+Dx\nCNefO4faikCuwzIJ7Dehi8jvgPOARlU9zN1XC9wDTAU2AB9T1ZbhC9OYzCiLG6IeW00H4Nan1/Ll\nM2bSE44yqiz5xL660VlP87Ljp/YOf99w07kAXHr7Kzz1TiPTrvsHAGt+cDZ/XbaFUr+XC+ZPpKUj\nyLqd7Rx1YO1Qv62M29neQ3Wpn627u/jzks2ceci43u/vX06anuPozECSaaH/AfgFcEfcvmuBxap6\nk4hc625/M/PhGZNZG5s7mTqmnA3NnTy5ylmJ/rTZ9fzq2bX86tm1wN6EPJDuUAS/18PuziA7Wnv4\n+vtnJ5zLpLW7b9fI51Y39d48Xb+zg3uXbqZhTzfv3vCBvOr6t6sjyIIbnmTCqFK27ekG4JsfODjH\nUZlk7LeGrqrPAfsWAs8HFrmPFwEXZDguY4bFmqZ2Zo7bO/fIt845mEmj+w5df/a9pt7H2/d08z+P\nv0swHEVVeXHNTk768dNcecdS/v76NgBOmVWf8L0+ecwUwKk9T6wp43N/WNr73E8Xr6bBTZbffXAl\nn/39EjqDue8bv3pHG0d+/wmA3mR+44cPZ2pdRS7DMklKt4Y+TlUbAFS1QUTGZjAmY4ZFKBJlY3MH\nZx4yjifedlrnH1swmZfXNfPHlzf2HnfzE+9x0ow6PB7hZ0+t5q5XNvGzp9YwtqqExrYeABa/08ji\ndxo5ckoNh00clfD9Pnb0ZM6fP4ESn5erT5/BN+9zWuePfOkkPvrLF+kMRgC4e8lmAI76/pM89bVT\nGD8qdyMvv3i3c0/gxx+dy0mz6jigurSg6/8jzbDfFBWRK4ErAaZMmTLcb2fMgDbt6iQUUWbUV/bu\nKwt4+cBh4/nT5QtZt7OdSFT53v+9zTE3PskHj5jAym2tAPg8wq6OIABXnXoQcyeO4om3d/C5E6cN\n+p6xUsoZc8YR8K7kvLnjmTO+mpeuOx2vR1i+sYUr7lhKTzhKVyjCL59Zy1WnHsTYqlK8nswk0paO\nIB4RRpUPfm9gd2eQne1BRpX5uWiBLR1XiCQ20GLQg0SmAg/F3RR9FzjVbZ2PB55R1dn7e50FCxbo\n0qVL93eYMcPiTy9v5Pq/v8UTXzmZM29+Dui/gHEoEmXmtx/pc97lJ07j/513CNGo4slQko23s72H\nUr+XI7//BMGw0zf+jDnj+OWnjuxdeDld7T1hDvuPxwAIeD1MHF3G7s4gHzxiAuccPp7HVm6nOxRl\nZ3tP76eWu/5lIcfHLfJsck9Elqnqgv0dl24L/UHgMuAm9+sDab6OMVmzekcbVaW+PjX0fVuhfq+H\njx89mc5ghE8snEJUleMPcpLbcCRzoHdx5evPncN3HljJSTPreHLVDmZ++xGe/8ZpTKgpG7C13h2K\n8J0H3mJCTRn/dspBfW7OdgbD3PXK3lJSKBqlKxihpTPEHS9t5I6XNvZ5rbrKEq47+2BL5gUsmW6L\ndwOnAnUisgX4D5xEfq+IXA5sAi4aziCNyYTNLV1JLZV200fnZiGa/j593FQuPfZARITDv/sYbd1h\nTvrx08yfUsOx08dw9mEHMHdSDQBbWjrZ2tLFxl2d3LvUGRj108Wr+cUlR3L0tNE89tZ2/t8DKwE4\ncUYdf/js0XT0RKgu89HSGSL+cjxLAAASC0lEQVQUifL1v77J7HGVXHPmbHxeGfKnAZN7SZVcMsVK\nLiaXTrjpKY48cDQ/v2Q+qxpa2drSxRmHjMt1WAl95NZ/snzTbsDpO98Vcm6gXnTUJK469SDe95Nn\nk3qdQydU8+crj6UqjUFTJn8Md8nFmLy2pzPEyoY9veWS3Z1Btu7u4lPHHgjAnPHVzBlfncsQB3XL\nxfP59XNr+e6HDsXv9fDBn7/Aiq17+MuyLfwlbqqCEp+Hu65YyNiqUtbt7KCxtZun321kyfpd3PrJ\nozhmWv4NWjLDx1ropiid89PnebuhlaXXn8E/VjTwHbf8cN9Vx+XlyMxktHQEuf6Bt3j4zQYAHv/K\nyVSU+JIqI5nCZi10M6K93eB0N/z6X97g3e3O8PwvnzGzYJM5wOiKAL+4ZD4Pv9nAZccdyKxxtjiz\n6csSuik63aEIIqAKT7/rjPq85eJ5XBA3U2ChEhHW3XgO1kXcJGK3tU1RWdPYxrfuX4EqnH6wM4D5\nxg8fXhTJPMbjERv0YxKyFropGq+sa+Zid2m5Y6fXcuunjmTltlaOnDI6x5EZkx2W0E1RCIajvcn8\n+nPncPHRkynxeS2ZmxHFEropCq9tcqbjP+fwA2y+bjNiWUI3eWXxqh3c8PAqaisCXHHSNCpL/Myb\nUkNliQ9VZcXWPWzb3U1NuZ+3t7UiAgGfh7+/thWvR/jhR3IzytOYfGAJ3eSV7z/0NhuaO1m/s4Nl\nG/cughXwefCK9I6Y3FdliY+bPnJ4SqsNGVNsLKGPQDtau9nVEcybkZKdwTA/XbyanlCUDc2dfOrY\nKXz6uKlsbO7E64FVDW20doXoCkWYPLqcybVltPdEWOiOgvR7PdSU+xOuGmTMSGIJvcD0hCM88Po2\nLjxy0qCz/4UiUVq7QoxxZ/KLeWltM5f8xrl5OLaqhKgqcyfVcPxBY5hYU0ZVqZ+F02v7TdSkqty3\nfCtjKgLMnTSK2ooAIkJzew8VJT68nr2TO4UjUVq7wwR8HvxeoaUjxD9WNBCJKqMrAqgqHhE8Hgh4\nvdz5ykZeXNsMOEPyv3LGLMZUlvQOnHnfwfk534ox+SarCV3VmWOjxO+hxOcZsC/tkvW7+MXTaxhd\n7udHH51Lqd+LqlrfW+CXz6zllidXUx7wct7cCQMed8UdS3nm3SbW//AcGtt6WHjjYgI+D+WBva3Y\nY6bVElXlne1tPPVOY5/zK0t8VJX6qKssoa4yQE842pt0wVnwoTzg7bNuZsDnodTnoa0nTKozSsRu\nZs6fXGP/z8akKasJ/e2GVo74z8d7t2eOrWT2AVVMr6sAEUIRZ8X1h99sYMXWPQA88Po2Kkt8dIUi\nzKivZHNLJweOqUBVqSjxUVPmJ6JKic9DRYmPEp+HEp8XjwiVpT6qSpxvsSzgpaLE2V8e8DGuuoQp\nteW094QJeD1Ul/l5/O0drGpoZWxVCQGfh0hUKfV58XmFrS1d1FQE2NrSRWWJlwPHVDC9voISn4ex\n1aVUJ5jNrjsUoamth7KAF7/HA0nkqeb2Hj79uyX84MOHM29yTb/nNzZ3AtCwu5s9XaHEL6LwjDtC\ncvOuLv778XcBp2tfMBzlsuMO5HvnH9bnlE3NnSzduIuWzhANu7uIKrT3hFjd2M6O1h46g2HmThrF\n5SdOY2d7kOb2Hlq7Q1SU+Kgu9RONKu09YbpDEUaV+RldESAUcd5vVHmAwyZUU+r30tYdZvyoUlQh\nokpPOEJFwMfk2vJ+34YxJjVZnZxr/IxD9YY/PMSbW3azqyNIqd/LG5t3967TGO9fT5nOpJoymjuC\n7OkKIQibdnWwprGdqlI/u7uCTKopZ2d7D+Go4vMIncEIwUiU7lCEjp4w0WH41mJDyuN5PcLMsZUc\nOmEUtRVOYg+Gozy5qpGtu7syH8QQfeucg7ny5INyHYYxJklZmZxLRD4A/BTwAr9V1ZsGO35iTRmX\nJ1iDUVXpDkUp9XvoDEZo7Q4xrqp0SCvEqCrhqLKnK4RXhLbuMFF3X2cwzPY93Wza1Ul3KELA5yEU\ncbL0+w8d57TwPUJTWw9j3JZmVyhCdamf8aNKCUeVNY3tbGzuJByN8uhb23nkre1saO5AFaKqvfXk\nS46ZzJzx1b2vn4z3trcx64CBJ15a09jGjLGDT8zkFWeIeCiiCM4fnfd2tDFrXBXnzxu4VGOMKVxp\nt9BFxAu8B5wJbAFeBS5R1bcHOqeYp89tauuhvqoEVSUSVXy2+osxJkOSbaEPJescA6xR1XWqGgT+\nDJw/hNcraPVVTm8SEbFkbozJiaFknonA5rjtLe4+Y4wxOTCUhJ6owN2vfiMiV4rIUhFZ2tTUNIS3\nM8YYM5ihJPQtwOS47UnAtn0PUtXbVHWBqi6or68fwtsZY4wZzFAS+qvATBGZJiIB4OPAg5kJyxhj\nTKrS7raoqmER+QLwGE63xd+p6sqMRWaMMSYlQ+qHrqr/AP6RoViMMcYMQVZHiopIE7Axa284NHXA\nzlwHkYJCireQYoXCireQYoXCijeXsR6oqvu9CZnVhF5IRGRpMh3580UhxVtIsUJhxVtIsUJhxVsI\nsdoIGGOMKRKW0I0xpkhYQh/YbbkOIEWFFG8hxQqFFW8hxQqFFW/ex2o1dGOMKRLWQjfGmCJhCd0Y\nY4rEiE3oIvIJETnCfWyLWGaYXd/hUYjXVUQKIs+IyIdEpKCX8iqIC51JInKGiDwP3ALMB9A8vpEg\nIheIyPdzHUeyCun6FtK1LaTrCr3J8Zpcx5EM99q+BNwOjM91PEOR1UWic8VtyZQCi4CxwA04i3GU\nu897VTWSuwj7cuP1AJ8FrgUOFJHHVfX53EaWWCFd30K6toV0XWNExAd8FbgKmCIiT6nq6/kWq3tt\nK4C7gSrgeuDLwIHACyLiUdVoDkNMy4hooaujC7hTVU9V1ceAF4FL3efz5gcNeuONAGtwWmOfB/K2\nJVlI17eQrm0hXdcYVQ0D7wIHA9cAv3b351Ws7rVtB/7kXtvFwKO4q64VYjKHIk/oInK1iPxGRK4A\nUNUH3P1eYD2wUkQmD/Ya2RQX77+4u55V1TZV/Q1QISKXu8flxf9bIV3fQrq2hXRdoTfem0TkY+6u\nh1W1W1VvAcaKyCfc4/y5i9IRF+tFAKp6j7vfC+wGNotISS5jHIqc//AOFxH5DPAJ4D7gUyLyLRGZ\nDr2thVbgCJz/xJzbJ95LReQ6YHrcId8BrhGR0fnQeiik61tI17bArquIyFeAi4GlwPfc+EfHHXYN\n8F8AqhrKepCuBLH+p4h8RkTq3dgiOH8sz1XVnlzFOVRFm9CB04EfqeqjODW9APCp2JOqugLowlmY\nIx/sG28p8MnYk6r6CLAKuFJEqmItjBwqpOtbSNe2YK6re1P2NOB6Vf0r8BWcPzbvjzvmb8B7IvI1\ncG5A5lmsH4g75kVgi4h8KBcxZkLRJfS4j8yvAecBqOpS4GVggoic4B4nwONAaS67fw0S70vExev6\nJvBDYDVwQDbjjCmk61tI1zbfr+u+7xUX71LgJDfeR4H3gENFZHbc4VcBPxaR7WRhIfk0Yj3YPa4a\neAfI2SeJoSr4hC4iB7hfPdDnZsY/AY+InOxuvwU0ABPc4xSn50BHNrt/icihIlIa2042XhGZAdwK\n/B04UlV/ns/x5uL6isgJEtePOJ+vbbqx5urnFiiL34iLdw1QJSKHu9vPAqNweo4gIvOA3+CUkI5U\n1UV5GGule1wrztrI47IQ47Ao2IQuIvNFZDFuD4XYf1rcX+PVwErgYnG6TG3BaXlNjXuZr6nq77IU\n71wReQGn69mYuP3JxrsH+IKqfkRV+y3GnYfxQpaur4gcKSKPA0/h/IKmGmvWrm0GYoXs/tweKyL3\nAf8rIme5Nw9j3RMBlgAR4EwR8anq2zit8Ni84c3A51X1oixc26HGCvBxVf3DcMY5nAouobs3N24G\n7gAWqeoVcc/F9x1tA57HqUH+tzh32Efj/IABoKrB7EXO9cBfVfXDqrrVjdebbLyq2qSqqwslXjfm\nYb2+IuIXkV/jzIL3M5z1bU9NNdZsXNtMxerGm5WfWxE5FeeTy/04XRE/BYx2f8/CbixrcBaMn4HT\nrx+gB3dlMlXd7Nb98znWDbHXUdXu4Y51OBVcQnc/ZlYBr6nqHQAiclB8Mhdn9N9dOC2v7+D8Qjzv\nbmfjI18vEfG4H63b3W5ciMiZIlIDiLt9g8WblhLgOeAkVX0I55d5jtv6irixfs9iTdtc4FVVvRP4\nE+DH+bmI/Z7dICK3A8tw/kgdIyLLgF04f7AKJdbHsxzr8FHVvP8HHAvMituuxvkr/B2cmuP9OC32\nI4FZOL8UM+KO9wBVOYy3Cuej9Hk4ddrH3Hivw/kobfGmESvu9M9xz10O/Cr2HM4v+V3AQRZrWj8H\n83AS3n8AO4BngN/hdP07PsHPQSVQY7Hm7l/OA9jPf1oN8DDOx9DrgYq4564GXgdOxmn9/Ainl0J9\n3DGePIr3W8By4EPu9snAA8BxFm/6sbrJ0OM+nuH+Mo+OPWexphVvZdxzx7iJ8aPu9uU4NzmPyJNr\nm7ex5uJfvpdcKnBah190H8fu/KOqPwNOU9Xn1BkI8Hecmxud0K+envN4gYdwWre17vZSYDvQDRZv\nEhLGqo6oe1Nxg3vMKbHnLNa04j0p9oSqLgHqcWviODdza4AWyItrm8+xZl3eJXQR+bSInCIi1erc\njLsNuBcnkSwUkQmxY1W1Je7Uo4DNOHexydZ/XBLxTnTjeRP4OvDvIlKHc9PmcPbemLN4U4811u1Q\n3Hhi3Stjf3TEYh1yvCU488d83j31dJw/8t3ZireQYs21vEjobs+V8SLyNHAZzii+X4pInTpzQnQC\nT+LcJHpf3HklInKqiCzFGZ12k2bhLnW68arq7Tizu30X+CjwL6q6yeIdWqyqqm5PkXacssaxsf0W\na9rxnu7G1QM8CFSKyHPAJThdPBst1jyU65oP4HW/zsKZ+QycaX1/Dty/z7FfwekXPQooc/cdD1xQ\nAPFWxe33W7wZjbXcYh2WeGvifs/KgOkWa37/y1kLXUR8InIjcKOInALMZm+5JIxz0/M497mY3+Dc\nnX4S2CAiE1T1RVX9e57H+wSwJvbRULMwSVEhxZuBWNdbrMMW7wYRmaiqXaq6zmLNbzlJ6O5/yDKc\nj0trcEZ7hoDTROQY6P0I+p84H/djzsWpj70OHK5ZGDGZoXjfsHgt1mzGmqF4Y79nWy3WApGLjwU4\nd6Yvjdu+FWcCn88Ay9x9Hpwhz/cCU9195wMnW7zFE6/FavEWWqz5/C83b+osoVXC3lrZJ4Efuo9f\nB77oPl4A3J3zi2TxWqwFFmuhxVtIsebzv5yUXFS1U1V7dO+yVGcCTe7jz+IMiX4Ip4fFcug/JWY2\nWbzDx2IdPoUUbyHFms9yuki0OLOhKc50lQ+6u9twRikeBqxXtyam7p/nXLJ4h4/FOnwKKd5CijUf\n5bofehRnEp2dwFz3L/D/A6Kq+oLm3w0Oi3f4WKzDp5DiLaRY80+uaz44AyuiwAvA5bmOx+K1WIst\n1kKLt5Bizbd/4l7AnBGRScClwP9oASzOavEOH4t1+BRSvIUUa77JeUI3xhiTGbmuoRtjjMkQS+jG\nGFMkLKEbY0yRsIRujDFFwhK6McYUCUvopmiJSEREXheRlSLyhohcI87yb4OdM1VEPpGtGI3JJEvo\npph1qeo8VT0UZ26Qc3BWhR/MVMASuilI1g/dFC0RaVfVyrjt6cCrQB1wIPBHnIWGwVmq7EUReRmY\nA6wHFgE/A24CTsWZDfB/VfXXWfsmjEmBJXRTtPZN6O6+FuBgnAmfoqraLSIzcaZkXSAipwJfU9Xz\n3OOvBMaq6g3iLEL8T+AiVV2f1W/GmCTkdLZFY3IgNuWqH/iFiMzDWeZs1gDHn4UzSdSF7vYoYCZO\nC96YvGIJ3YwYbsklAjTi1NJ3AEfg3EvqHug0nMUVHstKkMYMgd0UNSOCiNQDvwJ+oU6dcRTQoKpR\nnImgvO6hbUBV3KmPAVeJiN99nVkiUoExecha6KaYlYnI6zjllTDOTdD/cZ+7FbhPRC4CngY63P1v\nAmEReQP4A/BTnJ4vy90VcpqAC7L1DRiTCrspaowxRcJKLsYYUyQsoRtjTJGwhG6MMUXCEroxxhQJ\nS+jGGFMkLKEbY0yRsIRujDFFwhK6McYUif8PzWmjDqRu5F8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load and plot dataset\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# load dataset\n",
    "def parser(x):\n",
    "\treturn datetime.strptime('20'+x, '%Y-%m-%d')\n",
    "series = pandas.read_csv(\"/Users/kellyliu/Desktop/HMM/WWWWR.csv\", header=0, \n",
    "                     parse_dates=[0], index_col=0, squeeze=True, \n",
    "                     date_parser=parser)\n",
    "# summarize first few rows\n",
    "\n",
    "print(series.head())\n",
    "#line plot\n",
    "series.plot()\n",
    "\n",
    "pyplot.show()\n",
    "#Running the example loads the dataset as a Pandas Series "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic of 100, 500, 1000 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
    "\tcolumns.append(df)\n",
    "\tdf = concat(columns, axis=1)\n",
    "\tdf = df.drop(0)\n",
    "\treturn df\n",
    " \n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    " \n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    " \n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    " \n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, yhat):\n",
    "\tnew_row = [x for x in X] + [yhat]\n",
    "\tarray = numpy.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    " \n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "\tX, y = train[:, 0:-1], train[:, -1]\n",
    "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\treturn model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "while_loop() got an unexpected keyword argument 'maximum_iterations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8d7d411b26e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-8d7d411b26e9>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(repeats, series, epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mtrain_trimmed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mlstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_trimmed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0;31m# forecast the entire training dataset to build up state for forecasting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mtrain_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_trimmed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_trimmed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-4a78371551b2>\u001b[0m in \u001b[0;36mfit_lstm\u001b[0;34m(train, batch_size, nb_epoch, neurons)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_input_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstateful\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;31m# input shape: `(samples, time (padded with zeros), input_dim)`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m# note that the .build() method of subclasses MUST define\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0;31m# self.input_spec and self.state_spec with complete input shapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[1;32m    647\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list_or_none\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0mconstants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list_or_none\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length)\u001b[0m\n\u001b[1;32m   3009\u001b[0m         \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0mseed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mensure\u001b[0m \u001b[0mdeterminism\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3011\u001b[0;31m     \u001b[0;31m# Returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3012\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m     \"\"\"\n",
      "\u001b[0;31mTypeError\u001b[0m: while_loop() got an unexpected keyword argument 'maximum_iterations'"
     ]
    }
   ],
   "source": [
    "# run a repeated experiment\n",
    "def experiment(repeats, series, epochs):\n",
    "\t# transform data to be stationary\n",
    "\traw_values = series.values\n",
    "\tdiff_values = difference(raw_values, 1)\n",
    "\t# transform data to be supervised learning\n",
    "\tsupervised = timeseries_to_supervised(diff_values, 1)\n",
    "\tsupervised_values = supervised.values\n",
    "\t# split data into train and test-sets\n",
    "\ttrain, test = supervised_values[0:-12], supervised_values[-12:]\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\t# run experiment\n",
    "\terror_scores = list()\n",
    "\tfor r in range(repeats):\n",
    "\t\t# fit the model\n",
    "\t\tbatch_size = 4\n",
    "\t\ttrain_trimmed = train_scaled[2:, :]\n",
    "\t\tlstm_model = fit_lstm(train_trimmed, batch_size, epochs, 1)\n",
    "\t\t# forecast the entire training dataset to build up state for forecasting\n",
    "\t\ttrain_reshaped = train_trimmed[:, 0].reshape(len(train_trimmed), 1, 1)\n",
    "\t\tlstm_model.predict(train_reshaped, batch_size=batch_size)\n",
    "\t\t# forecast test dataset\n",
    "\t\ttest_reshaped = test_scaled[:,0:-1]\n",
    "\t\ttest_reshaped = test_reshaped.reshape(len(test_reshaped), 1, 1)\n",
    "\t\toutput = lstm_model.predict(test_reshaped, batch_size=batch_size)\n",
    "\t\tpredictions = list()\n",
    "\t\tfor i in range(len(output)):\n",
    "\t\t\tyhat = output[i,0]\n",
    "\t\t\tX = test_scaled[i, 0:-1]\n",
    "\t\t\t# invert scaling\n",
    "\t\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t\t# invert differencing\n",
    "\t\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t\t# store forecast\n",
    "\t\t\tpredictions.append(yhat)\n",
    "\t\t# report performance\n",
    "\t\trmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\n",
    "\t\tprint('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "\t\terror_scores.append(rmse)\n",
    "\treturn error_scores\n",
    " \n",
    " \n",
    "# load dataset\n",
    "series = pandas.read_csv(\"/Users/kellyliu/Desktop/HMM/WWWWR.csv\", header=0, \n",
    "                     parse_dates=[0], index_col=0, squeeze=True, \n",
    "                     date_parser=parser)\n",
    "repeats = 2\n",
    "results = DataFrame()\n",
    "# vary training epochs\n",
    "epochs = [100, 500, 1000 ]\n",
    "for e in epochs:\n",
    "\tresults[str(e)] = experiment(repeats, series, e)\n",
    "# summarize results\n",
    "print(results.describe())\n",
    "# save boxplot\n",
    "results.boxplot()\n",
    "pyplot.savefig('boxplot_epochs.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Larger Batch Size. \n",
    "- Explore larger batch sizes than 4, perhaps requiring further manipulation of the size of the training and test datasets.\n",
    "\n",
    "\n",
    "## Diagnostic of 1,2,4, Batch Size  (with epoch=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "In a stateful network, you should only pass inputs with a number of samples that can be divided by the batch size. Found: 952 samples",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8dd5eff75cd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-8dd5eff75cd5>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(repeats, series, batch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mtrain_trimmed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0mlstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_trimmed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0;31m# forecast the entire training dataset to build up state for forecasting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mtrain_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_trimmed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_trimmed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-4a78371551b2>\u001b[0m in \u001b[0;36mfit_lstm\u001b[0;34m(train, batch_size, nb_epoch, neurons)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1582\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1434\u001b[0m                                  \u001b[0;34m'a number of samples that can be '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m                                  \u001b[0;34m'divided by the batch size. Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m                                  str(x[0].shape[0]) + ' samples')\n\u001b[0m\u001b[1;32m   1437\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: In a stateful network, you should only pass inputs with a number of samples that can be divided by the batch size. Found: 952 samples"
     ]
    }
   ],
   "source": [
    "# run a repeated experiment\n",
    "def experiment(repeats, series, batch_size):\n",
    "\t# transform data to be stationary\n",
    "\traw_values = series.values\n",
    "\tdiff_values = difference(raw_values, 1)\n",
    "\t# transform data to be supervised learning\n",
    "\tsupervised = timeseries_to_supervised(diff_values, 1)\n",
    "\tsupervised_values = supervised.values\n",
    "\t# split data into train and test-sets\n",
    "\ttrain, test = supervised_values[0:-12], supervised_values[-12:]\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\t# run experiment\n",
    "\terror_scores = list()\n",
    "\tfor r in range(repeats):\n",
    "\t\t# fit the model\n",
    "\t\ttrain_trimmed = train_scaled[2:, :]\n",
    "\t\tlstm_model = fit_lstm(train_trimmed, batch_size, 1000, 1)\n",
    "\t\t# forecast the entire training dataset to build up state for forecasting\n",
    "\t\ttrain_reshaped = train_trimmed[:, 0].reshape(len(train_trimmed), 1, 1)\n",
    "\t\tlstm_model.predict(train_reshaped, batch_size=batch_size)\n",
    "\t\t# forecast test dataset\n",
    "\t\ttest_reshaped = test_scaled[:,0:-1]\n",
    "\t\ttest_reshaped = test_reshaped.reshape(len(test_reshaped), 1, 1)\n",
    "\t\toutput = lstm_model.predict(test_reshaped, batch_size=batch_size)\n",
    "\t\tpredictions = list()\n",
    "\t\tfor i in range(len(output)):\n",
    "\t\t\tyhat = output[i,0]\n",
    "\t\t\tX = test_scaled[i, 0:-1]\n",
    "\t\t\t# invert scaling\n",
    "\t\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t\t# invert differencing\n",
    "\t\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t\t# store forecast\n",
    "\t\t\tpredictions.append(yhat)\n",
    "\t\t# report performance\n",
    "\t\trmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\n",
    "\t\tprint('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "\t\terror_scores.append(rmse)\n",
    "\treturn error_scores\n",
    " \n",
    " \n",
    "# load dataset\n",
    "series = pandas.read_csv(\"/Users/kellyliu/Desktop/HMM/WWWWR.csv\", header=0, \n",
    "                     parse_dates=[0], index_col=0, squeeze=True, \n",
    "                     date_parser=parser)\n",
    "repeats = 2\n",
    "results = DataFrame()\n",
    "# vary training batches\n",
    "batches = [1]\n",
    "for b in batches:\n",
    "\tresults[str(b)] = experiment(repeats, series, b)\n",
    "# summarize results\n",
    "print(results.describe())\n",
    "# save boxplot\n",
    "results.boxplot()\n",
    "pyplot.savefig('boxplot_batches.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic of 1, 2, 3, 4, 5 neurons (epoch=1000, batch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "1) Test RMSE: 3.545\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# run a repeated experiment\n",
    "def experiment(repeats, series, neurons):\n",
    "\t# transform data to be stationary\n",
    "\traw_values = series.values\n",
    "\tdiff_values = difference(raw_values, 1)\n",
    "\t# transform data to be supervised learning\n",
    "\tsupervised = timeseries_to_supervised(diff_values, 1)\n",
    "\tsupervised_values = supervised.values\n",
    "\t# split data into train and test-sets\n",
    "\ttrain, test = supervised_values[0:-12], supervised_values[-12:]\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\t# run experiment\n",
    "\terror_scores = list()\n",
    "\tfor r in range(repeats):\n",
    "\t\t# fit the model\n",
    "\t\tbatch_size = 1\n",
    "\t\ttrain_trimmed = train_scaled[2:, :]\n",
    "\t\tlstm_model = fit_lstm(train_trimmed, batch_size, 1000, neurons)\n",
    "\t\t# forecast the entire training dataset to build up state for forecasting\n",
    "\t\ttrain_reshaped = train_trimmed[:, 0].reshape(len(train_trimmed), 1, 1)\n",
    "\t\tlstm_model.predict(train_reshaped, batch_size=batch_size)\n",
    "\t\t# forecast test dataset\n",
    "\t\ttest_reshaped = test_scaled[:,0:-1]\n",
    "\t\ttest_reshaped = test_reshaped.reshape(len(test_reshaped), 1, 1)\n",
    "\t\toutput = lstm_model.predict(test_reshaped, batch_size=batch_size)\n",
    "\t\tpredictions = list()\n",
    "\t\tfor i in range(len(output)):\n",
    "\t\t\tyhat = output[i,0]\n",
    "\t\t\tX = test_scaled[i, 0:-1]\n",
    "\t\t\t# invert scaling\n",
    "\t\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t\t# invert differencing\n",
    "\t\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t\t# store forecast\n",
    "\t\t\tpredictions.append(yhat)\n",
    "\t\t# report performance\n",
    "\t\trmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\n",
    "\t\tprint('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "\t\terror_scores.append(rmse)\n",
    "\treturn error_scores\n",
    " \n",
    " \n",
    "# load dataset\n",
    "series = pandas.read_csv(\"/Users/kellyliu/Desktop/HMM/WWWWR.csv\", header=0, \n",
    "                     parse_dates=[0], index_col=0, squeeze=True, \n",
    "                     date_parser=parser)\n",
    "repeats = 2\n",
    "results = DataFrame()\n",
    "# vary neurons\n",
    "neurons = [1]\n",
    "for n in neurons:\n",
    "\tresults[str(n)] = experiment(repeats, series, n)\n",
    "# summarize results\n",
    "print(results.describe())\n",
    "# save boxplot\n",
    "results.boxplot()\n",
    "pyplot.savefig('boxplot_neurons.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
